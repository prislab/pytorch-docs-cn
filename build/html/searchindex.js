Search.setIndex({docnames:["index","torchvision/datasets","torchvision/index","torchvision/models","torchvision/transforms","torchvision/utils"],envversion:53,filenames:["index.rst","torchvision/datasets.rst","torchvision/index.rst","torchvision/models.rst","torchvision/transforms.rst","torchvision/utils.rst"],objects:{"":{torchvision:[2,0,0,"-"]},"torchvision.datasets":{CIFAR100:[1,1,1,""],CIFAR10:[1,1,1,""],CocoCaptions:[1,1,1,""],CocoDetection:[1,1,1,""],FashionMNIST:[1,1,1,""],ImageFolder:[1,1,1,""],LSUN:[1,1,1,""],MNIST:[1,1,1,""],PhotoTour:[1,1,1,""],STL10:[1,1,1,""],SVHN:[1,1,1,""]},"torchvision.datasets.CIFAR10":{__getitem__:[1,2,1,""]},"torchvision.datasets.CocoCaptions":{__getitem__:[1,2,1,""]},"torchvision.datasets.CocoDetection":{__getitem__:[1,2,1,""]},"torchvision.datasets.ImageFolder":{__getitem__:[1,2,1,""]},"torchvision.datasets.LSUN":{__getitem__:[1,2,1,""]},"torchvision.datasets.PhotoTour":{__getitem__:[1,2,1,""]},"torchvision.datasets.STL10":{__getitem__:[1,2,1,""]},"torchvision.datasets.SVHN":{__getitem__:[1,2,1,""]},"torchvision.models":{alexnet:[3,3,1,""],densenet121:[3,3,1,""],densenet161:[3,3,1,""],densenet169:[3,3,1,""],densenet201:[3,3,1,""],inception_v3:[3,3,1,""],resnet101:[3,3,1,""],resnet152:[3,3,1,""],resnet18:[3,3,1,""],resnet34:[3,3,1,""],resnet50:[3,3,1,""],squeezenet1_0:[3,3,1,""],squeezenet1_1:[3,3,1,""],vgg11:[3,3,1,""],vgg11_bn:[3,3,1,""],vgg13:[3,3,1,""],vgg13_bn:[3,3,1,""],vgg16:[3,3,1,""],vgg16_bn:[3,3,1,""],vgg19:[3,3,1,""],vgg19_bn:[3,3,1,""]},"torchvision.transforms":{CenterCrop:[4,1,1,""],ColorJitter:[4,1,1,""],Compose:[4,1,1,""],FiveCrop:[4,1,1,""],Grayscale:[4,1,1,""],Lambda:[4,1,1,""],Normalize:[4,1,1,""],Pad:[4,1,1,""],RandomCrop:[4,1,1,""],RandomGrayscale:[4,1,1,""],RandomHorizontalFlip:[4,1,1,""],RandomResizedCrop:[4,1,1,""],RandomSizedCrop:[4,1,1,""],RandomVerticalFlip:[4,1,1,""],Resize:[4,1,1,""],Scale:[4,1,1,""],TenCrop:[4,1,1,""],ToPILImage:[4,1,1,""],ToTensor:[4,1,1,""]},"torchvision.transforms.Normalize":{__call__:[4,2,1,""]},"torchvision.transforms.ToPILImage":{__call__:[4,2,1,""]},"torchvision.transforms.ToTensor":{__call__:[4,2,1,""]},"torchvision.utils":{make_grid:[5,3,1,""],save_image:[5,3,1,""]},torchvision:{get_image_backend:[2,3,1,""],set_image_backend:[2,3,1,""]}},objnames:{"0":["py","module","Python \u6a21\u5757"],"1":["py","class","Python \u7c7b"],"2":["py","method","Python \u65b9\u6cd5"],"3":["py","function","Python \u51fd\u6570"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:function"},terms:{"0 ":4,"0)":4,"0,":[1,3,4,5],"0.":[3,4],"00":3,"07":3,"08 ":4,"08":4,"0]":4,"1 ":[3,4],"1)":[4,5],"1,":4,"1-":[3,4],"1.":[3,4],"10":1,"10)":4,"10-":1,"10.":3,"101 ":3,"101":3,"11 ":3,"11":3,"11-":3,"11.":3,"12":[2,3],"121 ":3,"121":3,"123.":1,"13 ":3,"13":3,"13-":3,"15":3,"152 ":3,"152":3,"16 ":3,"16":3,"16-":3,"161 ":3,"161":3,"169 ":3,"169":3,"18 ":3,"18":3,"19 ":3,"19":3,"19-":3,"19.":3,"1]":[1,3],"2 ":4,"2.":[3,4,5],"20":3,"20.":3,"201 ":3,"201":3,"21.":3,"22.":3,"224,":3,"224.":3,"224x224)":3,"225]":3,"229,":3,"23.":3,"24":3,"24.":3,"25.":3,"255]":4,"26.":3,"27.":3,"28.":3,"29.":3,"2d\n":4,"3 ":[3,4],"3)":4,"3,":4,"3-":3,"3.":4,"3/":4,"30.":3,"3333333333333333)":4,"34 ":3,"34":3,"35":3,"37":3,"38":3,"3l,":1,"4 ":4,"4,":1,"4/":4,"406]":3,"41":3,"41.":3,"427l,":1,"43":3,"43.":3,"44":3,"45":3,"456,":3,"485,":3,"4d ":[4,5],"4th ":1,"4x ":3,"5 ":3,"5.":[3,4],"50 ":3,"50":3,"50x ":3,"55":3,"58":3,"5d ":4,"5mb ":3,"6.":3,"62":3,"63":3,"640l)":1,"69":3,"7.":3,"70":3,"75":[3,4],"76":3,"8.":[3,5],"80":3,"81":3,"82783\n":1,"83":3,"85":3,"9.":3,"90":3,"91":3,"92":3,"94":3,"98":3,"\u6e90\u4ee3\u7801]":[1,2,3,4,5],"a ":[1,3,4,5],"a\"":3,"about ":4,"above ":1,"accimage'":2,"accordingly ":1,"accuracy ":3,"accuracy.":3,"across ":1,"again.":1,"alexnet ":3,"alexnet-":3,"all ":[1,3,4,5],"almost ":1,"already ":1,"amount ":5,"an ":[1,3,4,5],"and ":[1,2,3,4,5],"annotation ":1,"api ":1,"api.":1,"apply ":4,"architecture ":3,"architectures,":2,"architectures:":3,"are ":[1,3,4,5],"are'":1,"are.":1,"args.":1,"arguments ":5,"arguments:":1,"arranged ":1,"as ":[1,2,4,5],"asd932_.":1,"aspect ":4,"assign ":1,"assigns ":1,"assumed ":4,"assumptions ":4,"at ":[3,4],"autograd ":0,"available:":1,"avg ":4,"b ":[4,5],"b\"":3,"backend.":2,"background'":1,"batch ":[3,4,5],"batch_size=":1,"batches ":3,"batches-":1,"be ":[1,3,4,5],"bedroom_train'":1,"behind ":1,"below ":4,"best ":0,"blue ":1,"border.":4,"borders.":4,"bottom ":4,"bright ":1,"brightness)":4,"brightness,":4,"brightness.":4,"brightness=":4,"brightness]":4,"broadcasting ":0,"bs,":4,"but ":2,"by ":[1,3,4,5],"c ":[4,5],"c)":4,"c,":4,"c-":1,"calling ":[3,5],"can ":[1,3,4],"captions ":1,"cat/":1,"categories ":1,"category.":1,"center.":4,"centercrop(":4,"central ":4,"chained ":4,"change ":4,"channel ":[3,4],"channel,":4,"channel.":4,"channel:":4,"channel]":4,"channels ":4,"channels,":4,"chosen ":4,"church_train'":1,"cifar-":1,"class ":[1,4],"class":1,"class.":1,"class_index ":1,"classes=":1,"coco ":1,"coco.":1,"color ":4,"common ":[1,2,4],"compatible ":1,"compose(":4,"compose.":4,"composes ":4,"computation ":3,"computed ":5,"computer ":[2,3],"configuration ":3,"connected ":3,"consists ":2,"construct ":3,"constructed ":3,"constructor:":3,"constructs ":3,"contains ":3,"contrail ":1,"contrast ":4,"contrast)":4,"contrast.":4,"contrast=":4,"contrast]":4,"conversion ":2,"convert ":4,"converted ":4,"converts ":4,"convolutional ":3,"corners ":4,"covered ":1,"creates ":1,"crop ":[3,4],"crop)":4,"crop.":4,"crops ":4,"crops:":4,"crops]":4,"cuda ":0,"d\"":3,"darts ":1,"data ":[1,4],"data.":1,"data1,":1,"data2,":1,"data:":4,"data_loader ":1,"database ":1,"dataloader(":1,"dataset ":[1,4],"dataset,":1,"dataset.":1,"datasets ":1,"datasets,":2,"datasets.":1,"deal ":4,"default ":[4,5],"default)":4,"default,":5,"default:":4,"default_loader>":1,"defined ":4,"definitions ":3,"densely ":3,"densenet-":3,"deprecated ":4,"depth ":4,"descriptors ":1,"desired ":4,"determined ":4,"deviation.":4,"deviations ":4,"digit ":1,"dir ":1,"directory ":1,"directory.":1,"displayed ":5,"distance.":1,"dividing ":5,"do ":4,"documented ":5,"does ":2,"dog/":1,"download=":1,"downloaded ":1,"downloaded,":1,"downloads ":1,"e ":4,"e'":3,"e,":[1,4],"e.":[1,3,4],"e\"":3,"each ":[4,5],"edge ":4,"emitting ":1,"error ":3,"example ":[3,4],"example:":1,"exist.":1,"exists.":1,"expect ":[1,3],"expected ":[3,4],"extending ":0,"extra ":1,"extra'":1,"fashion-":2,"faster ":2,"favor ":4,"fewer ":3,"file'":1,"file.":[1,5],"files.":1,"fill ":4,"fill=":4,"final ":5,"finally ":4,"fivecrop(":4,"flip ":4,"flipped ":4,"flipping ":4,"float":[4,5],"floattensor ":4,"flying ":1,"following ":[1,3],"following:":4,"for ":[1,2,3,4,5],"found ":3,"four ":4,"from ":[1,3,4,5],"function ":[1,4],"function":[0,4],"function/":1,"functions ":1,"fuse ":4,"g ":4,"g,":[1,4],"g.":1,"generally ":2,"generic ":[1,2],"gets ":2,"given ":[1,4,5],"grayscale ":4,"grayscale.":4,"grid ":5,"grid.":5,"h ":[3,4,5],"h,":4,"has ":[1,3,4],"have ":[1,3],"height ":4,"hence,":1,"here ":1,"horizontal ":4,"horizontally ":4,"how ":4,"however,":1,"hue,":4,"hue.":4,"hue=":4,"hue]":4,"hue_factor ":4,"i,":4,"i.":[1,3,4],"if ":[1,3,4,5],"image ":[1,2,4,5],"image,":1,"image.":[1,4,5],"imagefolder(":1,"imagenet ":3,"imagenet-":2,"imagenet_data ":1,"imagenet_data,":1,"imagenet_root/":1,"images ":[1,3,4,5],"images.":[2,5],"implemented ":1,"implemented.":1,"import":[1,3],"in ":[1,3,4,5],"inception ":[2,4],"index ":1,"input ":[1,3,4],"input,":4,"input.":4,"input[":4,"inputs ":4,"instead ":4,"int ":4,"int":[1,4,5],"int,":4,"intel ":2,"internet ":1,"interpolation.":4,"interpolation=":4,"into ":[4,5],"ipp ":2,"is ":[1,4,5],"it ":[1,2,4],"it.":1,"its ":[1,3],"jitter ":4,"json ":1,"label ":1,"labels ":1,"lambda ":4,"lambda(":4,"lambda/":4,"layer ":3,"learning ":1,"least ":3,"leaves ":1,"left,":4,"left/":4,"length ":4,"less ":3,"library.":2,"like ":4,"list ":[1,4,5],"load ":[1,2],"load.":1,"loaded ":3,"loader ":1,"loader=":1,"local ":1,"location.":4,"loop ":4,"loss ":1,"m1,":4,"made ":4,"made.":4,"make ":5,"many ":2,"matched ":4,"matches)":1,"max ":5,"max(":4,"max)":5,"maximum ":5,"may ":4,"mean ":[3,4],"mean(":4,"mean:":4,"mean=":3,"mean[":4,"means ":4,"methods ":1,"min ":5,"min,":5,"mini-":[3,5],"minimum ":5,"mismatch ":4,"mn)":4,"mode=":4,"model ":3,"model(":4,"model.":3,"models ":3,"models,":3,"models.":3,"mountain ":1,"mountain.":1,"ms ":1,"much ":4,"multiple ":1,"multiprocessing ":0,"name ":[1,2],"ncrops,":4,"ndarray ":4,"networks.":4,"networks\"":3,"nn.":0,"no ":4,"normalization ":3,"normalize ":[3,4,5],"normalize(":3,"normalize:":3,"normalize=":5,"normalized ":[3,4],"normalized.":4,"not ":2,"note:":[1,4],"notebook ":5,"nrow)":5,"nrow,":5,"nrow=":5,"nsdf3.":1,"nthreads)":1,"num_output_channels ":4,"num_output_channels=":4,"num_workers=":1,"number ":[1,4,5],"number.":4,"numbers ":5,"numbers,":5,"numpy ":4,"numpy.":4,"object ":1,"of ":[1,2,3,4,5],"official ":3,"on ":[2,3],"one ":[1,2,3],"operations.":2,"optional ":4,"optional)":4,"or ":[1,4,5],"origin ":4,"original ":4,"other ":5,"otherwise ":1,"output ":4,"output:":1,"over ":[1,4,5],"overheard ":1,"p ":4,"p)":4,"p=":4,"package ":[0,2],"pad ":4,"pad\"":4,"pad_value=":5,"padded ":5,"padding ":4,"padding.":[4,5],"padding=":[4,5],"paper.":3,"parallelly ":1,"parameters ":3,"passed ":1,"passing ":3,"path ":1,"path.":1,"path/":1,"pil ":[1,2],"pil'":2,"pil,":2,"pil.":4,"pixel ":[4,5],"pixels.":5,"plane ":1,"plume ":1,"plus ":4,"popular ":2,"popularly ":4,"pre-":3,"preprocessed ":1,"preserving ":4,"pretrained=":3,"probability ":4,"processed/":1,"provide ":3,"provided ":4,"provided,":4,"puts ":1,"pytorch ":[1,3],"r ":4,"r,":4,"random ":[3,4],"randomly ":4,"randomresizedcrop.":4,"range ":[1,3,4,5],"range.":4,"range=":5,"rates ":3,"rather ":5,"ratio ":4,"ratio.":4,"ratio=":4,"require ":1,"rescaled ":4,"resize ":4,"resize.":4,"resized ":4,"resnet-":3,"respectively.":[1,4],"result ":4,"result.":4,"result_avg ":4,"rethinking ":3,"returned ":[1,4],"returns ":[1,3,4],"returns.":4,"rgb ":3,"right ":4,"right,":4,"root ":1,"root/":1,"row ":5,"s1,":4,"sacrificing ":3,"same ":[3,5],"samples ":1,"samples:":1,"saturation ":4,"saturation)":4,"saturation.":4,"saturation=":4,"saturation]":4,"save ":5,"saved.":5,"saves ":5,"scale ":5,"scale=":4,"scale_each=":5,"see ":[4,5],"selected.":1,"separately ":5,"sequence ":4,"serialization ":0,"set,":1,"set.":1,"several ":4,"shape ":[3,4,5],"shift ":5,"short":4,"should ":[1,4],"shuffle=":1,"sides ":4,"similar ":1,"simply ":1,"single ":4,"size ":[4,5],"size(":4,"size)":4,"size,":4,"size.":[4,5],"size:":1,"size\"":3,"sky ":1,"slightly ":3,"smaller ":4,"smoke ":1,"sn)":4,"snow'":1,"snowy ":1,"some ":4,"space ":4,"specifies ":2,"split=":1,"square ":4,"squeezenet ":3,"squeezenet:":3,"stack(":4,"standard ":4,"std ":3,"std:":4,"std=":3,"std[":4,"stream ":1,"subclass ":1,"subclasses ":1,"subpackage ":3,"subtracting ":5,"such ":3,"support ":2,"svhn ":1,"takes ":1,"target ":[1,4],"target)":1,"target_transform=":1,"targets ":4,"tencrop(":4,"tensor ":[4,5],"tensor,":[4,5],"tensor.":[4,5],"test ":[1,4],"test'":1,"test.":1,"than ":[2,3,5],"that ":[1,4],"the ":[1,2,3,4,5],"then ":[3,4,5],"there ":4,"these ":[1,3,4,5],"they ":[1,4],"this ":[1,4,5],"this.":4,"to ":[1,2,3,4,5],"to.":1,"to/":1,"together ":4,"together.":4,"top,":4,"top-":3,"top.":1,"top/":4,"torch.":[0,1,2,3],"torchvision ":0,"torchvision.":[0,2],"totensor(":4,"train ":4,"train'":1,"train+":1,"train=":1,"trained ":3,"training ":1,"training.":1,"transform ":[1,3,4],"transform.":4,"transform=":1,"transformations ":2,"transformed ":1,"transforms ":[1,2],"transforms.":[1,3,4],"trick.":3,"true":[1,3],"true,":[1,3,5],"tuple ":[1,4,5],"two ":1,"type ":4,"u'":1,"uniformly ":4,"unlabeled'":1,"use ":[3,4],"used ":[2,4,5],"user-":4,"uses ":2,"using ":[1,3,4],"utils.":[0,1,3,5],"v3 ":3,"val'":1,"value ":[4,5],"value.":[4,5],"version ":4,"version.":1,"vertical ":4,"vertical_flip=":4,"vertically ":4,"vgg ":3,"vgg-":3,"view ":1,"view(":4,"vision.":2,"vision\"":3,"w ":[3,4],"w)":[3,4,5],"way,":3,"way:":1,"we ":[1,3],"weights ":3,"weird ":3,"where ":[1,3,5],"which ":1,"while ":4,"width,":4,"will ":4,"with ":[1,3,4],"without ":3,"workers.":1,"x ":[3,4,5],"xxx.":1,"xxy.":1,"xxz.":1,"you ":[3,4],"your ":4,__call__:4,__getitem__:1,__len__:1,accimag:2,alexnet:2,an
:[1,4],and
:1,annfil:1,arg:4,as:[1,3],autograd:0,backend:2,bilinear:4,bool:[1,3,4,5],border
:4,borders
:4,bright:4,brightness_factor
:4,callabl:1,cap:1,centercrop:4,channel
:4,cifar100:1,cifar10:1,cifar:2,coco:2,cococapt:1,cocodetect:1,colorjitt:4,compos:4,contrast:4,contrast_factor
:4,crop
:4,crop:4,cuda:0,data:[0,1],dataload:1,dataset:[0,2],db_path:1,densenet121:3,densenet161:3,densenet169:3,densenet201:3,densenet:2,described
:1,directory
:1,distribut:0,download:1,dset:1,edg:4,error:3,exampl:[1,4,5],example
:3,fals:[1,3,4,5],fashionmnist:1,ffi:0,filenam:5,fill:4,fivecrop:4,from
:[3,4],get_image_backend:2,grayscal:4,here:[1,3,5],horizont:4,hue:4,imag:[2,4],image
:1,image:2,imagefold:2,imagenet:3,images
:4,img:1,incept:3,inception:3,inception_v3:3,index:1,init:0,instal:1,interpol:4,is
:[2,4],kwarg:[3,4,5],lambd:4,lambda:4,legaci:0,len:1,length
:4,level
:3,like
:4,list:[1,5],loadann:1,loader:1,lsun:2,make_grid:5,max
:5,mean:4,mechan:0,mnist:2,mode:4,model
:[2,3],model:[0,2],model_zoo:[0,3],multiprocess:[0,1],name:1,ncrops
:4,ndarrai:4,network:3,nn:0,none:[1,4,5],normal:[3,4,5],normalized
:3,not
:1,note:0,nrow:5,num_output_channel:4,object:4,of
:[1,4,5],onnx:0,optim:0,option:[1,4,5],otherwise
:1,pad:[4,5],pad_valu:5,padding
:4,parameters
:3,phototour:2,pic:4,png
:1,png:1,practic:0,pretrain:3,print:1,provided
:4,pt:1,py:1,pytorch:0,random
:4,randomcrop:[1,4],randomgrayscal:4,randomhorizontalflip:4,randomresizedcrop:4,randomsizedcrop:4,randomverticalflip:4,rang:5,range
:4,ratio:4,refer:[0,2],repo:3,resiz:4,resnet101:3,resnet152:3,resnet18:3,resnet34:3,resnet50:3,resnet:2,rgb:4,rgba:4,root:1,sampl:1,satur:4,saturation_factor
:4,save_imag:5,scale:4,scale_each:5,semant:0,sequenc:4,set_image_backend:2,shape
:4,size:[1,4],spars:0,split:1,squeezenet1_0:3,squeezenet1_1:3,squeezenet:2,std:4,stl10:2,stl10_binari:1,storag:0,string:[1,2],svhn:2,target:1,target_transform:1,tencrop:4,tensor
:4,tensor:[0,2,5],the
:[1,3],this
:4,to
:4,topilimag:4,torch:0,torchvis:0,totensor:[1,4],train:1,transform
:4,transform:[0,1,2],tupl:[1,4,5],unchanged
:4,util:[0,2],v3:2,vertical_flip:4,vgg11:3,vgg11_bn:3,vgg13:3,vgg13_bn:3,vgg16:3,vgg16_bn:3,vgg19:3,vgg19_bn:3,vgg:2,which
:1,with
:4},titles:["PyTorch documentation","torchvision.datasets","torchvision","torchvision.models","torchvision.transforms","torchvision.utils"],titleterms:{"12":1,"and ":0,"conversion ":4,"fashion-":1,"generic ":4,"imagenet-":1,"inception ":3,"indices ":0,"on ":4,"pil ":4,"pytorch ":0,"torch.":4,"torchvision.":[1,3,4,5],"transforms ":4,alexnet:3,caption:1,cifar:1,coco:1,dataset:1,densenet:3,detect:1,document:0,image:4,imagefold:1,lsun:1,mnist:1,model:3,phototour:1,resnet:3,squeezenet:3,stl10:1,svhn:1,tabl:0,tensor:4,torchvis:2,transform:4,util:5,v3:3,vgg:3}})