# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Torch Contributors
# This file is distributed under the same license as the PyTorch package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyTorch master (0.3.0.post4 )\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-01-12 11:13+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.1\n"

#: ../../source/notes/multiprocessing.rst:2
msgid "Multiprocessing best practices"
msgstr ""

#: ../../source/notes/multiprocessing.rst:4
msgid ""
":mod:`torch.multiprocessing` is a drop in replacement for Python's "
":mod:`python:multiprocessing` module. It supports the exact same "
"operations, but extends it, so that all tensors sent through a "
":class:`python:multiprocessing.Queue`, will have their data moved into "
"shared memory and will only send a handle to another process."
msgstr ""

#: ../../source/notes/multiprocessing.rst:12
msgid ""
"When a :class:`~torch.autograd.Variable` is sent to another process, both"
" the :attr:`Variable.data` and :attr:`Variable.grad.data` are going to be"
" shared."
msgstr ""

#: ../../source/notes/multiprocessing.rst:16
msgid ""
"This allows to implement various training methods, like Hogwild, A3C, or "
"any others that require asynchronous operation."
msgstr ""

#: ../../source/notes/multiprocessing.rst:20
msgid "Sharing CUDA tensors"
msgstr ""

#: ../../source/notes/multiprocessing.rst:22
msgid ""
"Sharing CUDA tensors between processes is supported only in Python 3, "
"using a ``spawn`` or ``forkserver`` start methods. "
":mod:`python:multiprocessing` in Python 2 can only create subprocesses "
"using ``fork``, and it's not supported by the CUDA runtime."
msgstr ""

#: ../../source/notes/multiprocessing.rst:29
msgid ""
"CUDA API requires that the allocation exported to other processes remains"
" valid as long as it's used by them. You should be careful and ensure "
"that CUDA tensors you shared don't go out of scope as long as it's "
"necessary. This shouldn't be a problem for sharing model parameters, but "
"passing other kinds of data should be done with care. Note that this "
"restriction doesn't apply to shared CPU memory."
msgstr ""

#: ../../source/notes/multiprocessing.rst:36
msgid "See also: :ref:`cuda-nn-dataparallel-instead`"
msgstr ""

#: ../../source/notes/multiprocessing.rst:40
msgid "Best practices and tips"
msgstr ""

#: ../../source/notes/multiprocessing.rst:43
msgid "Avoiding and fighting deadlocks"
msgstr ""

#: ../../source/notes/multiprocessing.rst:45
msgid ""
"There are a lot of things that can go wrong when a new process is "
"spawned, with the most common cause of deadlocks being background "
"threads. If there's any thread that holds a lock or imports a module, and"
" ``fork`` is called, it's very likely that the subprocess will be in a "
"corrupted state and will deadlock or fail in a different way. Note that "
"even if you don't, Python built in libraries do - no need to look further"
" than :mod:`python:multiprocessing`. "
":class:`python:multiprocessing.Queue` is actually a very complex class, "
"that spawns multiple threads used to serialize, send and receive objects,"
" and they can cause aforementioned problems too. If you find yourself in "
"such situation try using a "
":class:`~python:multiprocessing.queues.SimpleQueue`, that doesn't use any"
" additional threads."
msgstr ""

#: ../../source/notes/multiprocessing.rst:57
msgid ""
"We're trying our best to make it easy for you and ensure these deadlocks "
"don't happen but some things are out of our control. If you have any "
"issues you can't cope with for a while, try reaching out on forums, and "
"we'll see if it's an issue we can fix."
msgstr ""

#: ../../source/notes/multiprocessing.rst:63
msgid "Reuse buffers passed through a Queue"
msgstr ""

#: ../../source/notes/multiprocessing.rst:65
msgid ""
"Remember that each time you put a :class:`~torch.Tensor` into a "
":class:`python:multiprocessing.Queue`, it has to be moved into shared "
"memory. If it's already shared, it is a no-op, otherwise it will incur an"
" additional memory copy that can slow down the whole process. Even if you"
" have a pool of processes sending data to a single one, make it send the "
"buffers back - this is nearly free and will let you avoid a copy when "
"sending next batch."
msgstr ""

#: ../../source/notes/multiprocessing.rst:73
msgid "Asynchronous multiprocess training (e.g. Hogwild)"
msgstr ""

#: ../../source/notes/multiprocessing.rst:75
msgid ""
"Using :mod:`torch.multiprocessing`, it is possible to train a model "
"asynchronously, with parameters either shared all the time, or being "
"periodically synchronized. In the first case, we recommend sending over "
"the whole model object, while in the latter, we advise to only send the "
":meth:`~torch.nn.Module.state_dict`."
msgstr ""

#: ../../source/notes/multiprocessing.rst:81
msgid ""
"We recommend using :class:`python:multiprocessing.Queue` for passing all "
"kinds of PyTorch objects between processes. It is possible to e.g. "
"inherit the tensors and storages already in shared memory, when using the"
" ``fork`` start method, however it is very bug prone and should be used "
"with care, and only by advanced users. Queues, even though they're "
"sometimes a less elegant solution, will work properly in all cases."
msgstr ""

#: ../../source/notes/multiprocessing.rst:90
msgid ""
"You should be careful about having global statements, that are not "
"guarded with an ``if __name__ == '__main__'``. If a different start "
"method than ``fork`` is used, they will be executed in all subprocesses."
msgstr ""

#: ../../source/notes/multiprocessing.rst:95
msgid "Hogwild"
msgstr ""

#: ../../source/notes/multiprocessing.rst:97
msgid ""
"A concrete Hogwild implementation can be found in the `examples "
"repository`__, but to showcase the overall structure of the code, there's"
" also a minimal example below as well::"
msgstr ""

