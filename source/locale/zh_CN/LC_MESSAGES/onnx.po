# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Torch Contributors
# This file is distributed under the same license as the PyTorch package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyTorch master (0.3.0.post4 )\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-01-12 11:13+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.1\n"

#: ../../source/onnx.rst:2
msgid "torch.onnx"
msgstr ""

#: of torch.onnx:1
msgid ""
"The torch.onnx module contains functions to export models into the ONNX "
"IR format.  These models can be loaded with the ONNX library and then "
"converted to models which run on other deep learning frameworks."
msgstr ""

#: ../../source/onnx.rst:6
msgid "Example: End-to-end AlexNet from PyTorch to Caffe2"
msgstr ""

#: ../../source/onnx.rst:8
msgid ""
"Here is a simple script which exports a pretrained AlexNet as defined in "
"torchvision into ONNX.  It runs a single round of inference and then "
"saves the resulting traced model to ``alexnet.proto``::"
msgstr ""

#: ../../source/onnx.rst:20
msgid ""
"The resulting ``alexnet.proto`` is a binary protobuf file which contains "
"both the network structure and parameters of the model you exported (in "
"this case, AlexNet).  The keyword argument ``verbose=True`` causes the "
"exporter to print out a human-readable representation of the network::"
msgstr ""

#: ../../source/onnx.rst:53
msgid ""
"You can also verify the protobuf using the `onnx "
"<https://github.com/onnx/onnx/>`_ library. You can install ``onnx`` with "
"conda::"
msgstr ""

#: ../../source/onnx.rst:58
msgid "Then, you can run::"
msgstr ""

#: ../../source/onnx.rst:71
msgid ""
"To run the exported script with `caffe2 <https://caffe2.ai/>`_, you will "
"need three things:"
msgstr ""

#: ../../source/onnx.rst:73
msgid ""
"You'll need an install of Caffe2.  If you don't have one already, Please "
"`follow the install instructions <https://caffe2.ai/docs/getting-"
"started.html>`_."
msgstr ""

#: ../../source/onnx.rst:76
msgid ""
"You'll need `onnx-caffe2 <https://github.com/onnx/onnx-caffe2>`_, a pure-"
"Python library which provides a Caffe2 backend for ONNX.  You can install"
" ``onnx-caffe2`` with pip::"
msgstr ""

#: ../../source/onnx.rst:82
msgid "Once these are installed, you can use the backend for Caffe2::"
msgstr ""

#: ../../source/onnx.rst:98
msgid "In the future, there will be backends for other frameworks as well."
msgstr ""

#: ../../source/onnx.rst:101
msgid "Limitations"
msgstr ""

#: ../../source/onnx.rst:103
msgid ""
"The ONNX exporter is a *trace-based* exporter, which means that it "
"operates by executing your model once, and exporting the operators which "
"were actually run during this run.  This means that if your model is "
"dynamic, e.g., changes behavior depending on input data, the export won't"
" be accurate.  Similarly, a trace is likely to be valid only for a "
"specific input size (which is one reason why we require explicit inputs "
"on tracing.)  We recommend examining the model trace and making sure the "
"traced operators look reasonable."
msgstr ""

#: ../../source/onnx.rst:112
msgid ""
"PyTorch and Caffe2 often have implementations of operators with some "
"numeric differences.  Depending on model structure, these differences may"
" be negligible, but they can also cause major divergences in behavior "
"(especially on untrained models.)  In a future release, we plan to allow "
"Caffe2 to call directly to Torch implementations of operators, to help "
"you smooth over these differences when precision is important, and to "
"also document these differences."
msgstr ""

#: ../../source/onnx.rst:121
msgid "Supported operators"
msgstr ""

#: ../../source/onnx.rst:123
msgid "The following operators are supported:"
msgstr ""

#: ../../source/onnx.rst:125
msgid "add (nonzero alpha not supported)"
msgstr ""

#: ../../source/onnx.rst:126
msgid "sub (nonzero alpha not supported)"
msgstr ""

#: ../../source/onnx.rst:127
msgid "mul"
msgstr ""

#: ../../source/onnx.rst:128
msgid "div"
msgstr ""

#: ../../source/onnx.rst:129
msgid "cat"
msgstr ""

#: ../../source/onnx.rst:130
msgid "mm"
msgstr ""

#: ../../source/onnx.rst:131
msgid "addmm"
msgstr ""

#: ../../source/onnx.rst:132
msgid "neg"
msgstr ""

#: ../../source/onnx.rst:133
msgid "tanh"
msgstr ""

#: ../../source/onnx.rst:134
msgid "sigmoid"
msgstr ""

#: ../../source/onnx.rst:135
msgid "mean"
msgstr ""

#: ../../source/onnx.rst:136
msgid "t"
msgstr ""

#: ../../source/onnx.rst:137
msgid "expand (only when used before a broadcasting ONNX operator; e.g., add)"
msgstr ""

#: ../../source/onnx.rst:138
msgid "transpose"
msgstr ""

#: ../../source/onnx.rst:139
msgid "view"
msgstr ""

#: ../../source/onnx.rst:140
msgid "split"
msgstr ""

#: ../../source/onnx.rst:141
msgid "squeeze"
msgstr ""

#: ../../source/onnx.rst:142
msgid "prelu (single weight shared among input channels not supported)"
msgstr ""

#: ../../source/onnx.rst:143
msgid "threshold (non-zero threshold/non-zero value not supported)"
msgstr ""

#: ../../source/onnx.rst:144
msgid "leaky_relu"
msgstr ""

#: ../../source/onnx.rst:145
msgid "glu"
msgstr ""

#: ../../source/onnx.rst:146
msgid "softmax"
msgstr ""

#: ../../source/onnx.rst:147
msgid "avg_pool2d (ceil_mode not supported)"
msgstr ""

#: ../../source/onnx.rst:148
msgid "log_softmax"
msgstr ""

#: ../../source/onnx.rst:149
msgid "unfold (experimental support with ATen-Caffe2 integration)"
msgstr ""

#: ../../source/onnx.rst:150
msgid "elu"
msgstr ""

#: ../../source/onnx.rst:151
msgid "Conv"
msgstr ""

#: ../../source/onnx.rst:152
msgid "BatchNorm"
msgstr ""

#: ../../source/onnx.rst:153
msgid "MaxPool1d (ceil_mode not supported)"
msgstr ""

#: ../../source/onnx.rst:154
msgid "MaxPool2d (ceil_mode not supported)"
msgstr ""

#: ../../source/onnx.rst:155
msgid "MaxPool3d (ceil_mode not supported)"
msgstr ""

#: ../../source/onnx.rst:156
msgid "Embedding (no optional arguments supported)"
msgstr ""

#: ../../source/onnx.rst:157
msgid "RNN"
msgstr ""

#: ../../source/onnx.rst:158
msgid "ConstantPadNd"
msgstr ""

#: ../../source/onnx.rst:159
msgid "Dropout"
msgstr ""

#: ../../source/onnx.rst:160
msgid "FeatureDropout (training mode not supported)"
msgstr ""

#: ../../source/onnx.rst:161
msgid "Index (constant integer and tuple indices supported)"
msgstr ""

#: ../../source/onnx.rst:162
msgid "Negate"
msgstr ""

#: ../../source/onnx.rst:164
msgid "The operator set above is sufficient to export the following models:"
msgstr ""

#: ../../source/onnx.rst:166
msgid "AlexNet"
msgstr ""

#: ../../source/onnx.rst:167
msgid "DCGAN"
msgstr ""

#: ../../source/onnx.rst:168
msgid "DenseNet"
msgstr ""

#: ../../source/onnx.rst:169
msgid ""
"Inception (warning: this model is highly sensitive to changes in operator"
" implementation)"
msgstr ""

#: ../../source/onnx.rst:171
msgid "ResNet"
msgstr ""

#: ../../source/onnx.rst:172
msgid "SuperResolution"
msgstr ""

#: ../../source/onnx.rst:173
msgid "VGG"
msgstr ""

#: ../../source/onnx.rst:174
msgid ""
"`word_language_model "
"<https://github.com/pytorch/examples/tree/master/word_language_model>`_"
msgstr ""

#: ../../source/onnx.rst:176
msgid ""
"The interface for specifying operator definitions is highly experimental "
"and undocumented; adventurous users should note that the APIs will "
"probably change in a future interface."
msgstr ""

#: ../../source/onnx.rst:181
msgid "Functions"
msgstr ""

#: of torch.onnx.export:1
msgid ""
"Export a model into ONNX format.  This exporter runs your model once in "
"order to get a trace of its execution to be exported; at the moment, it "
"does not support dynamic models (e.g., RNNs.)"
msgstr ""

#: of torch.onnx.export:5
msgid "See also: :ref:`onnx-export`"
msgstr ""

#: of torch.onnx.export
msgid "参数"
msgstr ""

#: of torch.onnx.export:7
msgid "the model to be exported."
msgstr ""

#: of torch.onnx.export:9
msgid ""
"the inputs to the model, e.g., such that ``model(*args)`` is a valid "
"invocation of the model.  Any non-Variable arguments will be hard-coded "
"into the exported model; any Variable arguments will become inputs of the"
" exported model, in the order they occur in args.  If args is a Variable,"
" this is equivalent to having called it with a 1-ary tuple of that "
"Variable. (Note: passing keyword arguments to the model is not currently "
"supported.  Give us a shout if you need it.)"
msgstr ""

#: of torch.onnx.export:19
msgid ""
"a file-like object (has to implement fileno that returns a file "
"descriptor) or a string containing a file name.  A binary Protobuf will "
"be written to this file."
msgstr ""

#: of torch.onnx.export:22
msgid ""
"if specified, all parameters will be exported.  Set this to False if you "
"want to export an untrained model. In this case, the exported model will "
"first take all of its parameters as arguments, the ordering as specified "
"by ``model.state_dict().values()``"
msgstr ""

#: of torch.onnx.export:27
msgid ""
"if specified, we will print out a debug description of the trace being "
"exported."
msgstr ""

#: of torch.onnx.export:30
msgid ""
"export the model in training mode.  At the moment, ONNX is oriented "
"towards exporting models for inference only, so you will generally not "
"need to set this to True."
msgstr ""

